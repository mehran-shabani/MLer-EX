# Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„ÛŒ Ùˆ Ù…ÙˆØ§Ø±Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡

## Ù¾Ø±ÙˆÚ˜Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ¨

### ğŸŒ **ØªÙˆØ³Ø¹Ù‡ Frontend**

#### Û±. Ø§ÛŒØ¬Ø§Ø¯ React Component
```jsx
// Ø¯Ø±Ø®ÙˆØ§Ø³Øª: "ÛŒÚ© Ú©Ø§Ù…Ù¾ÙˆÙ†Ù†Øª UserCard Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§Ø±Ø¨Ø± Ø¨Ø³Ø§Ø²"

import React from 'react';
import { User } from '../types/User';
import './UserCard.css';

interface UserCardProps {
  user: User;
  onEdit?: (user: User) => void;
  onDelete?: (userId: string) => void;
  isEditable?: boolean;
}

const UserCard: React.FC<UserCardProps> = ({ 
  user, 
  onEdit, 
  onDelete, 
  isEditable = false 
}) => {
  const handleEdit = () => {
    if (onEdit && user) {
      onEdit(user);
    }
  };

  const handleDelete = () => {
    if (onDelete && user.id) {
      if (window.confirm('Ø¢ÛŒØ§ Ø§Ø² Ø­Ø°Ù Ø§ÛŒÙ† Ú©Ø§Ø±Ø¨Ø± Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø¯Ø§Ø±ÛŒØ¯ØŸ')) {
        onDelete(user.id);
      }
    }
  };

  return (
    <div className="user-card" data-testid="user-card">
      <div className="user-avatar">
        <img 
          src={user.avatar || '/default-avatar.png'} 
          alt={`${user.name} avatar`}
          onError={(e) => {
            e.currentTarget.src = '/default-avatar.png';
          }}
        />
      </div>
      
      <div className="user-info">
        <h3 className="user-name">{user.name}</h3>
        <p className="user-email">{user.email}</p>
        <p className="user-role">{user.role}</p>
        
        {user.lastLogin && (
          <span className="last-login">
            Ø¢Ø®Ø±ÛŒÙ† ÙˆØ±ÙˆØ¯: {new Date(user.lastLogin).toLocaleDateString('fa-IR')}
          </span>
        )}
      </div>
      
      {isEditable && (
        <div className="user-actions">
          <button 
            onClick={handleEdit}
            className="btn btn-primary"
            aria-label={`ÙˆÛŒØ±Ø§ÛŒØ´ ${user.name}`}
          >
            ÙˆÛŒØ±Ø§ÛŒØ´
          </button>
          <button 
            onClick={handleDelete}
            className="btn btn-danger"
            aria-label={`Ø­Ø°Ù ${user.name}`}
          >
            Ø­Ø°Ù
          </button>
        </div>
      )}
    </div>
  );
};

export default UserCard;
```

#### Û². State Management Ø¨Ø§ Redux
```typescript
// Ø¯Ø±Ø®ÙˆØ§Ø³Øª: "ÛŒÚ© Redux store Ø¨Ø±Ø§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø¨Ø³Ø§Ø²"

// types/user.ts
export interface User {
  id: string;
  name: string;
  email: string;
  role: 'admin' | 'user' | 'moderator';
  avatar?: string;
  lastLogin?: string;
  isActive: boolean;
}

export interface UserState {
  users: User[];
  loading: boolean;
  error: string | null;
  selectedUser: User | null;
}

// store/userSlice.ts
import { createSlice, createAsyncThunk, PayloadAction } from '@reduxjs/toolkit';
import { User, UserState } from '../types/user';
import { userApi } from '../services/userApi';

// Async thunks
export const fetchUsers = createAsyncThunk(
  'users/fetchUsers',
  async (_, { rejectWithValue }) => {
    try {
      const response = await userApi.getUsers();
      return response.data;
    } catch (error: any) {
      return rejectWithValue(error.message);
    }
  }
);

export const createUser = createAsyncThunk(
  'users/createUser',
  async (userData: Omit<User, 'id'>, { rejectWithValue }) => {
    try {
      const response = await userApi.createUser(userData);
      return response.data;
    } catch (error: any) {
      return rejectWithValue(error.message);
    }
  }
);

const initialState: UserState = {
  users: [],
  loading: false,
  error: null,
  selectedUser: null,
};

const userSlice = createSlice({
  name: 'users',
  initialState,
  reducers: {
    selectUser: (state, action: PayloadAction<User>) => {
      state.selectedUser = action.payload;
    },
    clearSelectedUser: (state) => {
      state.selectedUser = null;
    },
    clearError: (state) => {
      state.error = null;
    },
  },
  extraReducers: (builder) => {
    builder
      // Fetch users
      .addCase(fetchUsers.pending, (state) => {
        state.loading = true;
        state.error = null;
      })
      .addCase(fetchUsers.fulfilled, (state, action) => {
        state.loading = false;
        state.users = action.payload;
      })
      .addCase(fetchUsers.rejected, (state, action) => {
        state.loading = false;
        state.error = action.payload as string;
      })
      // Create user
      .addCase(createUser.fulfilled, (state, action) => {
        state.users.push(action.payload);
      });
  },
});

export const { selectUser, clearSelectedUser, clearError } = userSlice.actions;
export default userSlice.reducer;
```

### ğŸ”§ **ØªÙˆØ³Ø¹Ù‡ Backend**

#### Û±. Express.js API
```javascript
// Ø¯Ø±Ø®ÙˆØ§Ø³Øª: "ÛŒÚ© REST API Ú©Ø§Ù…Ù„ Ø¨Ø±Ø§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¨Ø³Ø§Ø²"

// models/Product.js
const mongoose = require('mongoose');

const productSchema = new mongoose.Schema({
  name: {
    type: String,
    required: [true, 'Ù†Ø§Ù… Ù…Ø­ØµÙˆÙ„ Ø§Ù„Ø²Ø§Ù…ÛŒ Ø§Ø³Øª'],
    trim: true,
    maxlength: [100, 'Ù†Ø§Ù… Ù…Ø­ØµÙˆÙ„ Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¨ÛŒØ´ Ø§Ø² 100 Ú©Ø§Ø±Ø§Ú©ØªØ± Ø¨Ø§Ø´Ø¯']
  },
  description: {
    type: String,
    required: [true, 'ØªÙˆØ¶ÛŒØ­Ø§Øª Ù…Ø­ØµÙˆÙ„ Ø§Ù„Ø²Ø§Ù…ÛŒ Ø§Ø³Øª'],
    maxlength: [1000, 'ØªÙˆØ¶ÛŒØ­Ø§Øª Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¨ÛŒØ´ Ø§Ø² 1000 Ú©Ø§Ø±Ø§Ú©ØªØ± Ø¨Ø§Ø´Ø¯']
  },
  price: {
    type: Number,
    required: [true, 'Ù‚ÛŒÙ…Øª Ù…Ø­ØµÙˆÙ„ Ø§Ù„Ø²Ø§Ù…ÛŒ Ø§Ø³Øª'],
    min: [0, 'Ù‚ÛŒÙ…Øª Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ù…Ù†ÙÛŒ Ø¨Ø§Ø´Ø¯']
  },
  category: {
    type: String,
    required: [true, 'Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø­ØµÙˆÙ„ Ø§Ù„Ø²Ø§Ù…ÛŒ Ø§Ø³Øª'],
    enum: ['electronics', 'clothing', 'books', 'home', 'sports']
  },
  stock: {
    type: Number,
    required: true,
    min: [0, 'Ù…ÙˆØ¬ÙˆØ¯ÛŒ Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ù…Ù†ÙÛŒ Ø¨Ø§Ø´Ø¯'],
    default: 0
  },
  images: [{
    url: String,
    alt: String
  }],
  isActive: {
    type: Boolean,
    default: true
  },
  tags: [String],
  createdBy: {
    type: mongoose.Schema.Types.ObjectId,
    ref: 'User',
    required: true
  }
}, {
  timestamps: true
});

// Indexes Ø¨Ø±Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¨Ù‡ØªØ±
productSchema.index({ name: 'text', description: 'text' });
productSchema.index({ category: 1, price: 1 });
productSchema.index({ createdAt: -1 });

module.exports = mongoose.model('Product', productSchema);

// controllers/productController.js
const Product = require('../models/Product');
const { validationResult } = require('express-validator');

class ProductController {
  // Ø¯Ø±ÛŒØ§ÙØª ØªÙ…Ø§Ù… Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¨Ø§ ÙÛŒÙ„ØªØ± Ùˆ ØµÙØ­Ù‡â€ŒØ¨Ù†Ø¯ÛŒ
  async getProducts(req, res) {
    try {
      const page = parseInt(req.query.page) || 1;
      const limit = parseInt(req.query.limit) || 10;
      const skip = (page - 1) * limit;
      
      const filter = {};
      
      // ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ Ø§Ø®ØªÛŒØ§Ø±ÛŒ
      if (req.query.category) {
        filter.category = req.query.category;
      }
      
      if (req.query.minPrice || req.query.maxPrice) {
        filter.price = {};
        if (req.query.minPrice) filter.price.$gte = parseFloat(req.query.minPrice);
        if (req.query.maxPrice) filter.price.$lte = parseFloat(req.query.maxPrice);
      }
      
      if (req.query.search) {
        filter.$text = { $search: req.query.search };
      }
      
      const products = await Product.find(filter)
        .populate('createdBy', 'name email')
        .sort({ createdAt: -1 })
        .skip(skip)
        .limit(limit);
      
      const total = await Product.countDocuments(filter);
      
      res.json({
        success: true,
        data: products,
        pagination: {
          page,
          limit,
          total,
          pages: Math.ceil(total / limit)
        }
      });
    } catch (error) {
      res.status(500).json({
        success: false,
        message: 'Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ù…Ø­ØµÙˆÙ„Ø§Øª',
        error: error.message
      });
    }
  }
  
  // Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø­ØµÙˆÙ„ Ø¬Ø¯ÛŒØ¯
  async createProduct(req, res) {
    try {
      // Ø¨Ø±Ø±Ø³ÛŒ validation errors
      const errors = validationResult(req);
      if (!errors.isEmpty()) {
        return res.status(400).json({
          success: false,
          message: 'Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ Ù†Ø§Ù…Ø¹ØªØ¨Ø±',
          errors: errors.array()
        });
      }
      
      const productData = {
        ...req.body,
        createdBy: req.user.id
      };
      
      const product = new Product(productData);
      await product.save();
      
      // Populate creator info
      await product.populate('createdBy', 'name email');
      
      res.status(201).json({
        success: true,
        message: 'Ù…Ø­ØµÙˆÙ„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯',
        data: product
      });
    } catch (error) {
      if (error.name === 'ValidationError') {
        const validationErrors = Object.values(error.errors).map(err => err.message);
        return res.status(400).json({
          success: false,
          message: 'Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§',
          errors: validationErrors
        });
      }
      
      res.status(500).json({
        success: false,
        message: 'Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø­ØµÙˆÙ„',
        error: error.message
      });
    }
  }
}

module.exports = new ProductController();
```

### ğŸ“± **ØªÙˆØ³Ø¹Ù‡ Mobile**

#### Û±. React Native App
```javascript
// Ø¯Ø±Ø®ÙˆØ§Ø³Øª: "ÛŒÚ© Ø§Ù¾ Ù…ÙˆØ¨Ø§ÛŒÙ„ Ø¨Ø±Ø§ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø¢Ù†Ù„Ø§ÛŒÙ† Ø¨Ø³Ø§Ø²"

// screens/ProductListScreen.js
import React, { useState, useEffect } from 'react';
import {
  View,
  Text,
  FlatList,
  Image,
  TouchableOpacity,
  StyleSheet,
  RefreshControl,
  ActivityIndicator
} from 'react-native';
import { useNavigation } from '@react-navigation/native';

const ProductListScreen = () => {
  const [products, setProducts] = useState([]);
  const [loading, setLoading] = useState(true);
  const [refreshing, setRefreshing] = useState(false);
  const navigation = useNavigation();

  useEffect(() => {
    fetchProducts();
  }, []);

  const fetchProducts = async () => {
    try {
      const response = await fetch('https://api.example.com/products');
      const data = await response.json();
      setProducts(data.products);
    } catch (error) {
      console.error('Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ù…Ø­ØµÙˆÙ„Ø§Øª:', error);
    } finally {
      setLoading(false);
      setRefreshing(false);
    }
  };

  const onRefresh = () => {
    setRefreshing(true);
    fetchProducts();
  };

  const renderProduct = ({ item }) => (
    <TouchableOpacity
      style={styles.productCard}
      onPress={() => navigation.navigate('ProductDetail', { productId: item.id })}
      accessibilityLabel={`Ù…Ø­ØµÙˆÙ„ ${item.name}`}
    >
      <Image 
        source={{ uri: item.images[0]?.url }} 
        style={styles.productImage}
        resizeMode="cover"
      />
      <View style={styles.productInfo}>
        <Text style={styles.productName} numberOfLines={2}>
          {item.name}
        </Text>
        <Text style={styles.productPrice}>
          {item.price.toLocaleString('fa-IR')} ØªÙˆÙ…Ø§Ù†
        </Text>
        <View style={styles.productMeta}>
          <Text style={styles.productCategory}>{item.category}</Text>
          <Text style={styles.productStock}>
            Ù…ÙˆØ¬ÙˆØ¯ÛŒ: {item.stock}
          </Text>
        </View>
      </View>
    </TouchableOpacity>
  );

  if (loading) {
    return (
      <View style={styles.loadingContainer}>
        <ActivityIndicator size="large" color="#007AFF" />
        <Text style={styles.loadingText}>Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ...</Text>
      </View>
    );
  }

  return (
    <View style={styles.container}>
      <FlatList
        data={products}
        renderItem={renderProduct}
        keyExtractor={(item) => item.id}
        numColumns={2}
        refreshControl={
          <RefreshControl refreshing={refreshing} onRefresh={onRefresh} />
        }
        contentContainerStyle={styles.listContainer}
      />
    </View>
  );
};

const styles = StyleSheet.create({
  container: {
    flex: 1,
    backgroundColor: '#f5f5f5',
  },
  listContainer: {
    padding: 10,
  },
  productCard: {
    flex: 1,
    margin: 5,
    backgroundColor: 'white',
    borderRadius: 12,
    shadowColor: '#000',
    shadowOffset: { width: 0, height: 2 },
    shadowOpacity: 0.1,
    shadowRadius: 4,
    elevation: 3,
  },
  productImage: {
    width: '100%',
    height: 150,
    borderTopLeftRadius: 12,
    borderTopRightRadius: 12,
  },
  productInfo: {
    padding: 12,
  },
  productName: {
    fontSize: 16,
    fontWeight: 'bold',
    color: '#333',
    marginBottom: 8,
  },
  productPrice: {
    fontSize: 18,
    fontWeight: '600',
    color: '#007AFF',
    marginBottom: 8,
  },
  productMeta: {
    flexDirection: 'row',
    justifyContent: 'space-between',
  },
  productCategory: {
    fontSize: 12,
    color: '#666',
    backgroundColor: '#f0f0f0',
    paddingHorizontal: 8,
    paddingVertical: 4,
    borderRadius: 6,
  },
  productStock: {
    fontSize: 12,
    color: '#666',
  },
  loadingContainer: {
    flex: 1,
    justifyContent: 'center',
    alignItems: 'center',
  },
  loadingText: {
    marginTop: 10,
    color: '#666',
  },
});

export default ProductListScreen;
```

#### Û². Flutter App Development
```dart
// Ø¯Ø±Ø®ÙˆØ§Ø³Øª: "ÛŒÚ© ØµÙØ­Ù‡ Ù„ÛŒØ³Øª Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¯Ø± Flutter Ø¨Ø³Ø§Ø²"

import 'package:flutter/material.dart';
import 'package:http/http.dart' as http;
import 'dart:convert';

class Product {
  final String id;
  final String name;
  final String description;
  final double price;
  final String imageUrl;
  final int stock;

  Product({
    required this.id,
    required this.name,
    required this.description,
    required this.price,
    required this.imageUrl,
    required this.stock,
  });

  factory Product.fromJson(Map<String, dynamic> json) {
    return Product(
      id: json['id'],
      name: json['name'],
      description: json['description'],
      price: json['price'].toDouble(),
      imageUrl: json['imageUrl'] ?? '',
      stock: json['stock'],
    );
  }
}

class ProductListScreen extends StatefulWidget {
  @override
  _ProductListScreenState createState() => _ProductListScreenState();
}

class _ProductListScreenState extends State<ProductListScreen> {
  List<Product> products = [];
  bool isLoading = true;
  String? error;

  @override
  void initState() {
    super.initState();
    fetchProducts();
  }

  Future<void> fetchProducts() async {
    try {
      final response = await http.get(
        Uri.parse('https://api.example.com/products'),
        headers: {'Content-Type': 'application/json'},
      );

      if (response.statusCode == 200) {
        final data = json.decode(response.body);
        setState(() {
          products = (data['products'] as List)
              .map((item) => Product.fromJson(item))
              .toList();
          isLoading = false;
        });
      } else {
        throw Exception('Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ù…Ø­ØµÙˆÙ„Ø§Øª');
      }
    } catch (e) {
      setState(() {
        error = e.toString();
        isLoading = false;
      });
    }
  }

  @override
  Widget build(BuildContext context) {
    return Scaffold(
      appBar: AppBar(
        title: Text('Ù…Ø­ØµÙˆÙ„Ø§Øª'),
        backgroundColor: Colors.blue[600],
        foregroundColor: Colors.white,
      ),
      body: isLoading
          ? Center(
              child: Column(
                mainAxisAlignment: MainAxisAlignment.center,
                children: [
                  CircularProgressIndicator(),
                  SizedBox(height: 16),
                  Text('Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ...'),
                ],
              ),
            )
          : error != null
              ? Center(
                  child: Column(
                    mainAxisAlignment: MainAxisAlignment.center,
                    children: [
                      Icon(Icons.error, size: 64, color: Colors.red),
                      SizedBox(height: 16),
                      Text(error!),
                      SizedBox(height: 16),
                      ElevatedButton(
                        onPressed: () {
                          setState(() {
                            isLoading = true;
                            error = null;
                          });
                          fetchProducts();
                        },
                        child: Text('ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯'),
                      ),
                    ],
                  ),
                )
              : RefreshIndicator(
                  onRefresh: fetchProducts,
                  child: GridView.builder(
                    padding: EdgeInsets.all(16),
                    gridDelegate: SliverGridDelegateWithFixedCrossAxisCount(
                      crossAxisCount: 2,
                      crossAxisSpacing: 16,
                      mainAxisSpacing: 16,
                      childAspectRatio: 0.75,
                    ),
                    itemCount: products.length,
                    itemBuilder: (context, index) {
                      final product = products[index];
                      return ProductCard(product: product);
                    },
                  ),
                ),
    );
  }
}

class ProductCard extends StatelessWidget {
  final Product product;

  const ProductCard({Key? key, required this.product}) : super(key: key);

  @override
  Widget build(BuildContext context) {
    return Card(
      elevation: 4,
      shape: RoundedRectangleBorder(
        borderRadius: BorderRadius.circular(12),
      ),
      child: InkWell(
        onTap: () {
          Navigator.pushNamed(
            context,
            '/product-detail',
            arguments: product.id,
          );
        },
        borderRadius: BorderRadius.circular(12),
        child: Column(
          crossAxisAlignment: CrossAxisAlignment.start,
          children: [
            Expanded(
              flex: 3,
              child: Container(
                decoration: BoxDecoration(
                  borderRadius: BorderRadius.vertical(top: Radius.circular(12)),
                  image: DecorationImage(
                    image: NetworkImage(product.imageUrl),
                    fit: BoxFit.cover,
                    onError: (error, stackTrace) {
                      // Handle image loading error
                    },
                  ),
                ),
              ),
            ),
            Expanded(
              flex: 2,
              child: Padding(
                padding: EdgeInsets.all(12),
                child: Column(
                  crossAxisAlignment: CrossAxisAlignment.start,
                  children: [
                    Text(
                      product.name,
                      style: TextStyle(
                        fontWeight: FontWeight.bold,
                        fontSize: 14,
                      ),
                      maxLines: 2,
                      overflow: TextOverflow.ellipsis,
                    ),
                    Spacer(),
                    Text(
                      '${product.price.toStringAsFixed(0)} ØªÙˆÙ…Ø§Ù†',
                      style: TextStyle(
                        color: Colors.blue[600],
                        fontWeight: FontWeight.w600,
                        fontSize: 16,
                      ),
                    ),
                    SizedBox(height: 4),
                    Text(
                      'Ù…ÙˆØ¬ÙˆØ¯ÛŒ: ${product.stock}',
                      style: TextStyle(
                        color: Colors.grey[600],
                        fontSize: 12,
                      ),
                    ),
                  ],
                ),
              ),
            ),
          ],
        ),
      ),
    );
  }
}
```

## Ù¾Ø±ÙˆÚ˜Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹Ù„ÙˆÙ… Ø¯Ø§Ø¯Ù‡

### ğŸ“Š **ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡ Ø¨Ø§ Python**

#### Û±. Data Analysis Pipeline
```python
# Ø¯Ø±Ø®ÙˆØ§Ø³Øª: "ÛŒÚ© pipeline Ú©Ø§Ù…Ù„ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ±ÙˆØ´ Ø¨Ø³Ø§Ø²"

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª matplotlib Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['figure.figsize'] = (12, 8)

class SalesAnalyzer:
    def __init__(self, data_path: str):
        """
        ØªØ­Ù„ÛŒÙ„Ú¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ±ÙˆØ´
        
        Args:
            data_path: Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ±ÙˆØ´
        """
        self.data_path = data_path
        self.df = None
        self.cleaned_df = None
        
    def load_data(self):
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ùˆ Ø¨Ø±Ø±Ø³ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§"""
        try:
            self.df = pd.read_csv(self.data_path)
            print(f"âœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯: {self.df.shape[0]} Ø±Ú©ÙˆØ±Ø¯ØŒ {self.df.shape[1]} Ø³ØªÙˆÙ†")
            
            # Ù†Ù…Ø§ÛŒØ´ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ù„ÛŒ
            print("\nğŸ“Š Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ù„ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§:")
            print(self.df.info())
            
            print("\nğŸ“ˆ Ø¢Ù…Ø§Ø± ØªÙˆØµÛŒÙÛŒ:")
            print(self.df.describe())
            
            return True
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§: {e}")
            return False
    
    def clean_data(self):
        """ØªÙ…ÛŒØ²Ø³Ø§Ø²ÛŒ Ùˆ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§"""
        if self.df is None:
            print("âŒ Ø§Ø¨ØªØ¯Ø§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ù†ÛŒØ¯")
            return False
            
        self.cleaned_df = self.df.copy()
        
        # ØªØ¨Ø¯ÛŒÙ„ ØªØ§Ø±ÛŒØ®â€ŒÙ‡Ø§
        date_columns = ['order_date', 'delivery_date']
        for col in date_columns:
            if col in self.cleaned_df.columns:
                self.cleaned_df[col] = pd.to_datetime(self.cleaned_df[col])
        
        # Ø­Ø°Ù Ù…Ù‚Ø§Ø¯ÛŒØ± null
        initial_rows = len(self.cleaned_df)
        self.cleaned_df = self.cleaned_df.dropna(subset=['order_id', 'customer_id', 'amount'])
        removed_rows = initial_rows - len(self.cleaned_df)
        
        if removed_rows > 0:
            print(f"ğŸ§¹ {removed_rows} Ø±Ú©ÙˆØ±Ø¯ Ù†Ø§Ù‚Øµ Ø­Ø°Ù Ø´Ø¯")
        
        # Ø­Ø°Ù Ù…Ù‚Ø§Ø¯ÛŒØ± Ù…Ù†ÙÛŒ
        self.cleaned_df = self.cleaned_df[self.cleaned_df['amount'] > 0]
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ø§ØªÛŒ
        if 'order_date' in self.cleaned_df.columns:
            self.cleaned_df['year'] = self.cleaned_df['order_date'].dt.year
            self.cleaned_df['month'] = self.cleaned_df['order_date'].dt.month
            self.cleaned_df['day_of_week'] = self.cleaned_df['order_date'].dt.day_name()
        
        print(f"âœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ ØªÙ…ÛŒØ² Ø´Ø¯: {len(self.cleaned_df)} Ø±Ú©ÙˆØ±Ø¯ Ø¨Ø§Ù‚ÛŒ Ù…Ø§Ù†Ø¯")
        return True
    
    def analyze_sales_trends(self):
        """ØªØ­Ù„ÛŒÙ„ Ø±ÙˆÙ†Ø¯Ù‡Ø§ÛŒ ÙØ±ÙˆØ´"""
        if self.cleaned_df is None:
            print("âŒ Ø§Ø¨ØªØ¯Ø§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø±Ø§ ØªÙ…ÛŒØ² Ú©Ù†ÛŒØ¯")
            return
        
        # ÙØ±ÙˆØ´ Ù…Ø§Ù‡Ø§Ù†Ù‡
        monthly_sales = self.cleaned_df.groupby(['year', 'month'])['amount'].agg([
            'sum', 'count', 'mean'
        ]).reset_index()
        
        monthly_sales['date'] = pd.to_datetime(monthly_sales[['year', 'month']].assign(day=1))
        
        # Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø± ÙØ±ÙˆØ´ Ù…Ø§Ù‡Ø§Ù†Ù‡
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # Ù†Ù…ÙˆØ¯Ø§Ø± 1: Ù…Ø¬Ù…ÙˆØ¹ ÙØ±ÙˆØ´ Ù…Ø§Ù‡Ø§Ù†Ù‡
        axes[0, 0].plot(monthly_sales['date'], monthly_sales['sum'], marker='o')
        axes[0, 0].set_title('Ù…Ø¬Ù…ÙˆØ¹ ÙØ±ÙˆØ´ Ù…Ø§Ù‡Ø§Ù†Ù‡')
        axes[0, 0].set_xlabel('Ù…Ø§Ù‡')
        axes[0, 0].set_ylabel('Ù…Ø¨Ù„Øº ÙØ±ÙˆØ´')
        axes[0, 0].tick_params(axis='x', rotation=45)
        
        # Ù†Ù…ÙˆØ¯Ø§Ø± 2: ØªØ¹Ø¯Ø§Ø¯ Ø³ÙØ§Ø±Ø´Ø§Øª Ù…Ø§Ù‡Ø§Ù†Ù‡
        axes[0, 1].bar(monthly_sales['date'], monthly_sales['count'], alpha=0.7)
        axes[0, 1].set_title('ØªØ¹Ø¯Ø§Ø¯ Ø³ÙØ§Ø±Ø´Ø§Øª Ù…Ø§Ù‡Ø§Ù†Ù‡')
        axes[0, 1].set_xlabel('Ù…Ø§Ù‡')
        axes[0, 1].set_ylabel('ØªØ¹Ø¯Ø§Ø¯ Ø³ÙØ§Ø±Ø´')
        
        # Ù†Ù…ÙˆØ¯Ø§Ø± 3: Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…Ø¨Ù„Øº Ø³ÙØ§Ø±Ø´
        axes[1, 0].plot(monthly_sales['date'], monthly_sales['mean'], 
                       marker='s', color='green')
        axes[1, 0].set_title('Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…Ø¨Ù„Øº Ø³ÙØ§Ø±Ø´ Ù…Ø§Ù‡Ø§Ù†Ù‡')
        axes[1, 0].set_xlabel('Ù…Ø§Ù‡')
        axes[1, 0].set_ylabel('Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…Ø¨Ù„Øº')
        
        # Ù†Ù…ÙˆØ¯Ø§Ø± 4: ÙØ±ÙˆØ´ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø±ÙˆØ² Ù‡ÙØªÙ‡
        daily_sales = self.cleaned_df.groupby('day_of_week')['amount'].sum()
        day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
        daily_sales = daily_sales.reindex(day_order)
        
        axes[1, 1].bar(range(len(daily_sales)), daily_sales.values)
        axes[1, 1].set_title('ÙØ±ÙˆØ´ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø±ÙˆØ² Ù‡ÙØªÙ‡')
        axes[1, 1].set_xlabel('Ø±ÙˆØ² Ù‡ÙØªÙ‡')
        axes[1, 1].set_ylabel('Ù…Ø¬Ù…ÙˆØ¹ ÙØ±ÙˆØ´')
        axes[1, 1].set_xticks(range(len(daily_sales)))
        axes[1, 1].set_xticklabels(['Ø¯ÙˆØ´Ù†Ø¨Ù‡', 'Ø³Ù‡â€ŒØ´Ù†Ø¨Ù‡', 'Ú†Ù‡Ø§Ø±Ø´Ù†Ø¨Ù‡', 'Ù¾Ù†Ø¬â€ŒØ´Ù†Ø¨Ù‡', 'Ø¬Ù…Ø¹Ù‡', 'Ø´Ù†Ø¨Ù‡', 'ÛŒÚ©Ø´Ù†Ø¨Ù‡'])
        
        plt.tight_layout()
        plt.show()
        
        return monthly_sales
    
    def customer_segmentation(self):
        """ØªÙ‚Ø³ÛŒÙ…â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø´ØªØ±ÛŒØ§Ù† Ø¨Ø± Ø§Ø³Ø§Ø³ RFM"""
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ RFM
        current_date = self.cleaned_df['order_date'].max()
        
        rfm = self.cleaned_df.groupby('customer_id').agg({
            'order_date': lambda x: (current_date - x.max()).days,  # Recency
            'order_id': 'count',  # Frequency
            'amount': 'sum'  # Monetary
        }).reset_index()
        
        rfm.columns = ['customer_id', 'recency', 'frequency', 'monetary']
        
        # ØªÙ‚Ø³ÛŒÙ…â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ù‡ quartile Ù‡Ø§
        rfm['r_score'] = pd.qcut(rfm['recency'], 4, labels=[4, 3, 2, 1])
        rfm['f_score'] = pd.qcut(rfm['frequency'].rank(method='first'), 4, labels=[1, 2, 3, 4])
        rfm['m_score'] = pd.qcut(rfm['monetary'], 4, labels=[1, 2, 3, 4])
        
        # Ø§ÛŒØ¬Ø§Ø¯ RFM Score
        rfm['rfm_score'] = rfm['r_score'].astype(str) + rfm['f_score'].astype(str) + rfm['m_score'].astype(str)
        
        # ØªØ¹Ø±ÛŒÙ segments
        def segment_customers(row):
            if row['rfm_score'] in ['444', '443', '434', '344']:
                return 'Champions'
            elif row['rfm_score'] in ['433', '343', '334', '333']:
                return 'Loyal Customers'
            elif row['rfm_score'] in ['431', '341', '314', '313']:
                return 'Potential Loyalists'
            elif row['rfm_score'] in ['421', '411', '321', '311']:
                return 'New Customers'
            elif row['rfm_score'] in ['422', '412', '322', '312']:
                return 'Promising'
            elif row['rfm_score'] in ['142', '132', '123', '122']:
                return 'At Risk'
            elif row['rfm_score'] in ['141', '131', '121', '111']:
                return 'Cannot Lose Them'
            else:
                return 'Others'
        
        rfm['segment'] = rfm.apply(segment_customers, axis=1)
        
        # Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬
        segment_summary = rfm['segment'].value_counts()
        print("ğŸ“Š ØªÙ‚Ø³ÛŒÙ…â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø´ØªØ±ÛŒØ§Ù†:")
        print(segment_summary)
        
        # Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø± segments
        plt.figure(figsize=(10, 6))
        segment_summary.plot(kind='bar')
        plt.title('ØªÙ‚Ø³ÛŒÙ…â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø´ØªØ±ÛŒØ§Ù† Ø¨Ø± Ø§Ø³Ø§Ø³ RFM')
        plt.xlabel('Ù†ÙˆØ¹ Ù…Ø´ØªØ±ÛŒ')
        plt.ylabel('ØªØ¹Ø¯Ø§Ø¯')
        plt.xticks(rotation=45)
        plt.tight_layout()
        plt.show()
        
        return rfm

# Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú©Ù„Ø§Ø³
analyzer = SalesAnalyzer('sales_data.csv')
analyzer.load_data()
analyzer.clean_data()
trends = analyzer.analyze_sales_trends()
rfm_analysis = analyzer.customer_segmentation()
```

### ğŸ§  **Machine Learning Projects**

#### Û±. Prediction Model
```python
# Ø¯Ø±Ø®ÙˆØ§Ø³Øª: "ÛŒÚ© Ù…Ø¯Ù„ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù‚ÛŒÙ…Øª Ø®Ø§Ù†Ù‡ Ø¨Ø³Ø§Ø²"

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import joblib

class HousePricePredictor:
    def __init__(self):
        self.models = {}
        self.scaler = StandardScaler()
        self.label_encoders = {}
        self.feature_names = []
        
    def load_and_prepare_data(self, file_path: str):
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ùˆ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§"""
        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
        self.df = pd.read_csv(file_path)
        print(f"ğŸ“Š Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯: {self.df.shape}")
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ù‚Ø§Ø¯ÛŒØ± null
        null_counts = self.df.isnull().sum()
        if null_counts.sum() > 0:
            print("âš ï¸ Ù…Ù‚Ø§Ø¯ÛŒØ± null ÛŒØ§ÙØª Ø´Ø¯:")
            print(null_counts[null_counts > 0])
        
        # ØªÙ…ÛŒØ²Ø³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
        self.df = self.df.dropna()
        
        # Ø­Ø°Ù outliers
        numeric_columns = self.df.select_dtypes(include=[np.number]).columns
        for col in numeric_columns:
            if col != 'price':  # Ù‚ÛŒÙ…Øª Ø±Ø§ Ù†Ú¯Ù‡ Ù…ÛŒâ€ŒØ¯Ø§Ø±ÛŒÙ…
                Q1 = self.df[col].quantile(0.25)
                Q3 = self.df[col].quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                self.df = self.df[(self.df[col] >= lower_bound) & (self.df[col] <= upper_bound)]
        
        print(f"âœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ ØªÙ…ÛŒØ² Ø´Ø¯: {self.df.shape}")
        
    def feature_engineering(self):
        """Ù…Ù‡Ù†Ø¯Ø³ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒ"""
        # Ø§ÛŒØ¬Ø§Ø¯ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯
        self.df['price_per_sqft'] = self.df['price'] / self.df['sqft_living']
        self.df['total_rooms'] = self.df['bedrooms'] + self.df['bathrooms']
        self.df['age'] = 2024 - self.df['yr_built']
        
        # ØªØ¨Ø¯ÛŒÙ„ Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ categorical
        categorical_columns = self.df.select_dtypes(include=['object']).columns
        
        for col in categorical_columns:
            if col != 'price':  # Ø§Ú¯Ø± Ù‚ÛŒÙ…Øª string Ø¨Ø§Ø´Ø¯
                le = LabelEncoder()
                self.df[col] = le.fit_transform(self.df[col])
                self.label_encoders[col] = le
        
        print("ğŸ”§ Ù…Ù‡Ù†Ø¯Ø³ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯")
        
    def train_models(self):
        """Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù"""
        # ØªØ¹Ø±ÛŒÙ features Ùˆ target
        X = self.df.drop(['price'], axis=1)
        y = self.df['price']
        
        self.feature_names = X.columns.tolist()
        
        # ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        # Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ø³Ø§Ø²ÛŒ
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        # ØªØ¹Ø±ÛŒÙ Ù…Ø¯Ù„â€ŒÙ‡Ø§
        models = {
            'Linear Regression': LinearRegression(),
            'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),
            'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42)
        }
        
        # Ø¢Ù…ÙˆØ²Ø´ Ùˆ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§
        results = {}
        
        for name, model in models.items():
            print(f"\nğŸ¤– Ø¢Ù…ÙˆØ²Ø´ {name}...")
            
            if name == 'Linear Regression':
                model.fit(X_train_scaled, y_train)
                y_pred = model.predict(X_test_scaled)
            else:
                model.fit(X_train, y_train)
                y_pred = model.predict(X_test)
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§
            mae = mean_absolute_error(y_test, y_pred)
            mse = mean_squared_error(y_test, y_pred)
            rmse = np.sqrt(mse)
            r2 = r2_score(y_test, y_pred)
            
            results[name] = {
                'model': model,
                'mae': mae,
                'rmse': rmse,
                'r2': r2,
                'predictions': y_pred
            }
            
            print(f"ğŸ“Š Ù†ØªØ§ÛŒØ¬ {name}:")
            print(f"  MAE: {mae:,.0f}")
            print(f"  RMSE: {rmse:,.0f}")
            print(f"  RÂ²: {r2:.3f}")
        
        self.models = results
        
        # Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„
        best_model_name = max(results.keys(), key=lambda x: results[x]['r2'])
        self.best_model = results[best_model_name]['model']
        print(f"\nğŸ† Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„: {best_model_name}")
        
        return results
    
    def visualize_results(self):
        """ØªØµÙˆÛŒØ±ÛŒâ€ŒØ³Ø§Ø²ÛŒ Ù†ØªØ§ÛŒØ¬"""
        if not self.models:
            print("âŒ Ø§Ø¨ØªØ¯Ø§ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø±Ø§ Ø¢Ù…ÙˆØ²Ø´ Ø¯Ù‡ÛŒØ¯")
            return
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§
        model_names = list(self.models.keys())
        r2_scores = [self.models[name]['r2'] for name in model_names]
        
        axes[0, 0].bar(model_names, r2_scores)
        axes[0, 0].set_title('Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¯Ù‚Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ (RÂ² Score)')
        axes[0, 0].set_ylabel('RÂ² Score')
        axes[0, 0].tick_params(axis='x', rotation=45)
        
        # Feature importance (Ø¨Ø±Ø§ÛŒ Random Forest)
        if 'Random Forest' in self.models:
            rf_model = self.models['Random Forest']['model']
            feature_importance = pd.DataFrame({
                'feature': self.feature_names,
                'importance': rf_model.feature_importances_
            }).sort_values('importance', ascending=False).head(10)
            
            axes[0, 1].barh(feature_importance['feature'], feature_importance['importance'])
            axes[0, 1].set_title('Ø§Ù‡Ù…ÛŒØª ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ (Random Forest)')
            axes[0, 1].set_xlabel('Ø§Ù‡Ù…ÛŒØª')
        
        # ØªÙˆØ²ÛŒØ¹ Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§
        axes[1, 0].hist(self.df['price'], bins=50, alpha=0.7)
        axes[1, 0].set_title('ØªÙˆØ²ÛŒØ¹ Ù‚ÛŒÙ…Øª Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§')
        axes[1, 0].set_xlabel('Ù‚ÛŒÙ…Øª')
        axes[1, 0].set_ylabel('ÙØ±Ø§ÙˆØ§Ù†ÛŒ')
        
        # Ø±Ø§Ø¨Ø·Ù‡ Ù‚ÛŒÙ…Øª Ùˆ Ù…ØªØ±Ø§Ú˜
        axes[1, 1].scatter(self.df['sqft_living'], self.df['price'], alpha=0.5)
        axes[1, 1].set_title('Ø±Ø§Ø¨Ø·Ù‡ Ù‚ÛŒÙ…Øª Ùˆ Ù…ØªØ±Ø§Ú˜')
        axes[1, 1].set_xlabel('Ù…ØªØ±Ø§Ú˜ (ÙÙˆØª Ù…Ø±Ø¨Ø¹)')
        axes[1, 1].set_ylabel('Ù‚ÛŒÙ…Øª')
        
        plt.tight_layout()
        plt.show()
    
    def predict_price(self, house_features: dict):
        """Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù‚ÛŒÙ…Øª Ø®Ø§Ù†Ù‡ Ø¬Ø¯ÛŒØ¯"""
        if self.best_model is None:
            print("âŒ Ø§Ø¨ØªØ¯Ø§ Ù…Ø¯Ù„ Ø±Ø§ Ø¢Ù…ÙˆØ²Ø´ Ø¯Ù‡ÛŒØ¯")
            return None
        
        # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ DataFrame
        features_df = pd.DataFrame([house_features])
        
        # Ø§Ø¹Ù…Ø§Ù„ label encoders
        for col, encoder in self.label_encoders.items():
            if col in features_df.columns:
                features_df[col] = encoder.transform(features_df[col])
        
        # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
        if isinstance(self.best_model, LinearRegression):
            features_scaled = self.scaler.transform(features_df)
            prediction = self.best_model.predict(features_scaled)[0]
        else:
            prediction = self.best_model.predict(features_df)[0]
        
        return prediction
    
    def save_model(self, file_path: str):
        """Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„ Ø¢Ù…ÙˆØ²Ø´â€ŒØ¯ÛŒØ¯Ù‡"""
        model_data = {
            'model': self.best_model,
            'scaler': self.scaler,
            'label_encoders': self.label_encoders,
            'feature_names': self.feature_names
        }
        
        joblib.dump(model_data, file_path)
        print(f"ğŸ’¾ Ù…Ø¯Ù„ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {file_path}")

# Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú©Ù„Ø§Ø³
predictor = HousePricePredictor()
predictor.load_and_prepare_data('house_data.csv')
predictor.feature_engineering()
results = predictor.train_models()
predictor.visualize_results()

# Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¨Ø±Ø§ÛŒ Ø®Ø§Ù†Ù‡ Ø¬Ø¯ÛŒØ¯
new_house = {
    'bedrooms': 3,
    'bathrooms': 2,
    'sqft_living': 2000,
    'sqft_lot': 5000,
    'floors': 2,
    'waterfront': 0,
    'view': 2,
    'condition': 3,
    'grade': 7,
    'yr_built': 1990
}

predicted_price = predictor.predict_price(new_house)
print(f"ğŸ’° Ù‚ÛŒÙ…Øª Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø´Ø¯Ù‡: {predicted_price:,.0f} Ø¯Ù„Ø§Ø±")
```

## Ù¾Ø±ÙˆÚ˜Ù‡â€ŒÙ‡Ø§ÛŒ DevOps

### ğŸ³ **Docker Ùˆ Containerization**

#### Û±. Multi-stage Dockerfile
```dockerfile
# Ø¯Ø±Ø®ÙˆØ§Ø³Øª: "ÛŒÚ© Dockerfile Ø¨Ù‡ÛŒÙ†Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ù¾Ù„ÛŒÚ©ÛŒØ´Ù† Node.js Ø¨Ø³Ø§Ø²"

# Build stage
FROM node:18-alpine AS builder

# Ù†ØµØ¨ dependencies Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ø¨Ø±Ø§ÛŒ build
RUN apk add --no-cache python3 make g++

WORKDIR /app

# Ú©Ù¾ÛŒ package files
COPY package*.json ./
COPY yarn.lock* ./

# Ù†ØµØ¨ dependencies
RUN npm ci --only=production && npm cache clean --force

# Ú©Ù¾ÛŒ source code
COPY . .

# Build application
RUN npm run build

# Runtime stage
FROM node:18-alpine AS runtime

# Ø§ÛŒØ¬Ø§Ø¯ non-root user Ø¨Ø±Ø§ÛŒ Ø§Ù…Ù†ÛŒØª
RUN addgroup -g 1001 -S nodejs && \
    adduser -S nextjs -u 1001

WORKDIR /app

# Ú©Ù¾ÛŒ ÙÙ‚Ø· ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²
COPY --from=builder /app/dist ./dist
COPY --from=builder /app/node_modules ./node_modules
COPY --from=builder /app/package.json ./package.json

# ØªÙ†Ø¸ÛŒÙ… permissions
RUN chown -R nextjs:nodejs /app
USER nextjs

# ØªÙ†Ø¸ÛŒÙ… environment variables
ENV NODE_ENV=production
ENV PORT=3000

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:3000/health || exit 1

# Expose port
EXPOSE 3000

# Start application
CMD ["npm", "start"]
```

#### Û². Docker Compose Setup
```yaml
# Ø¯Ø±Ø®ÙˆØ§Ø³Øª: "ÛŒÚ© docker-compose Ø¨Ø±Ø§ÛŒ full-stack app Ø¨Ø³Ø§Ø²"

version: '3.8'

services:
  # Frontend (React)
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    environment:
      - REACT_APP_API_URL=http://localhost:5000/api
    depends_on:
      - backend
    volumes:
      - ./frontend:/app
      - /app/node_modules
    networks:
      - app-network

  # Backend (Node.js)
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "5000:5000"
    environment:
      - NODE_ENV=development
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=myapp
      - DB_USER=postgres
      - DB_PASS=password
      - REDIS_URL=redis://redis:6379
      - JWT_SECRET=your-secret-key
    depends_on:
      - postgres
      - redis
    volumes:
      - ./backend:/app
      - /app/node_modules
    networks:
      - app-network

  # Database (PostgreSQL)
  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=myapp
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./database/init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - app-network

  # Cache (Redis)
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - app-network

  # Nginx (Reverse Proxy)
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
    depends_on:
      - frontend
      - backend
    networks:
      - app-network

volumes:
  postgres_data:
  redis_data:

networks:
  app-network:
    driver: bridge
```

#### Û³. Kubernetes Deployment
```yaml
# Ø¯Ø±Ø®ÙˆØ§Ø³Øª: "ØªÙ†Ø¸ÛŒÙ…Ø§Øª Kubernetes Ø¨Ø±Ø§ÛŒ deploy Ú©Ø±Ø¯Ù† app Ø¨Ø³Ø§Ø²"

# namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: myapp-production

---
# configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
  namespace: myapp-production
data:
  NODE_ENV: "production"
  API_URL: "https://api.myapp.com"
  LOG_LEVEL: "info"

---
# secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: app-secrets
  namespace: myapp-production
type: Opaque
data:
  DB_PASSWORD: cGFzc3dvcmQ=  # base64 encoded
  JWT_SECRET: eW91ci1zZWNyZXQta2V5  # base64 encoded

---
# deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: backend-deployment
  namespace: myapp-production
spec:
  replicas: 3
  selector:
    matchLabels:
      app: backend
  template:
    metadata:
      labels:
        app: backend
    spec:
      containers:
      - name: backend
        image: myapp/backend:latest
        ports:
        - containerPort: 5000
        env:
        - name: NODE_ENV
          valueFrom:
            configMapKeyRef:
              name: app-config
              key: NODE_ENV
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: DB_PASSWORD
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 5000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 5000
          initialDelaySeconds: 5
          periodSeconds: 5

---
# service.yaml
apiVersion: v1
kind: Service
metadata:
  name: backend-service
  namespace: myapp-production
spec:
  selector:
    app: backend
  ports:
  - protocol: TCP
    port: 80
    targetPort: 5000
  type: ClusterIP

---
# ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: app-ingress
  namespace: myapp-production
  annotations:
    kubernetes.io/ingress.class: "nginx"
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    nginx.ingress.kubernetes.io/rate-limit: "100"
spec:
  tls:
  - hosts:
    - api.myapp.com
    secretName: app-tls
  rules:
  - host: api.myapp.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: backend-service
            port:
              number: 80
```

## Ù¾Ø±ÙˆÚ˜Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ®ØµØµÛŒ

### ğŸ” **Ø³ÛŒØ³ØªÙ… Ø§Ø­Ø±Ø§Ø² Ù‡ÙˆÛŒØª Ú©Ø§Ù…Ù„**

#### Û±. JWT Authentication System
```javascript
// Ø¯Ø±Ø®ÙˆØ§Ø³Øª: "ÛŒÚ© Ø³ÛŒØ³ØªÙ… Ú©Ø§Ù…Ù„ Ø§Ø­Ø±Ø§Ø² Ù‡ÙˆÛŒØª Ø¨Ø§ JWT Ø¨Ø³Ø§Ø²"

// middleware/auth.js
const jwt = require('jsonwebtoken');
const bcrypt = require('bcryptjs');
const rateLimit = require('express-rate-limit');
const User = require('../models/User');

// Rate limiting Ø¨Ø±Ø§ÛŒ login
const loginLimiter = rateLimit({
  windowMs: 15 * 60 * 1000, // 15 Ø¯Ù‚ÛŒÙ‚Ù‡
  max: 5, // Ø­Ø¯Ø§Ú©Ø«Ø± 5 ØªÙ„Ø§Ø´
  message: {
    error: 'ØªØ¹Ø¯Ø§Ø¯ ØªÙ„Ø§Ø´â€ŒÙ‡Ø§ÛŒ ÙˆØ±ÙˆØ¯ Ø¨ÛŒØ´ Ø§Ø² Ø­Ø¯ Ù…Ø¬Ø§Ø². Ù„Ø·ÙØ§Ù‹ 15 Ø¯Ù‚ÛŒÙ‚Ù‡ ØµØ¨Ø± Ú©Ù†ÛŒØ¯.'
  },
  standardHeaders: true,
  legacyHeaders: false,
});

class AuthService {
  // ØªÙˆÙ„ÛŒØ¯ JWT token
  generateTokens(userId) {
    const accessToken = jwt.sign(
      { userId, type: 'access' },
      process.env.JWT_ACCESS_SECRET,
      { expiresIn: '15m' }
    );
    
    const refreshToken = jwt.sign(
      { userId, type: 'refresh' },
      process.env.JWT_REFRESH_SECRET,
      { expiresIn: '7d' }
    );
    
    return { accessToken, refreshToken };
  }
  
  // ØªØ£ÛŒÛŒØ¯ access token
  verifyAccessToken(token) {
    try {
      return jwt.verify(token, process.env.JWT_ACCESS_SECRET);
    } catch (error) {
      throw new Error('ØªÙˆÚ©Ù† Ù†Ø§Ù…Ø¹ØªØ¨Ø± ÛŒØ§ Ù…Ù†Ù‚Ø¶ÛŒ Ø´Ø¯Ù‡');
    }
  }
  
  // ØªØ£ÛŒÛŒØ¯ refresh token
  verifyRefreshToken(token) {
    try {
      return jwt.verify(token, process.env.JWT_REFRESH_SECRET);
    } catch (error) {
      throw new Error('ØªÙˆÚ©Ù† ØªØ§Ø²Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù†Ø§Ù…Ø¹ØªØ¨Ø±');
    }
  }
  
  // hash Ú©Ø±Ø¯Ù† Ø±Ù…Ø² Ø¹Ø¨ÙˆØ±
  async hashPassword(password) {
    const saltRounds = 12;
    return await bcrypt.hash(password, saltRounds);
  }
  
  // Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø±Ù…Ø² Ø¹Ø¨ÙˆØ±
  async comparePassword(password, hashedPassword) {
    return await bcrypt.compare(password, hashedPassword);
  }
}

// Middleware Ø¨Ø±Ø§ÛŒ ØªØ£ÛŒÛŒØ¯ authentication
const authenticateToken = async (req, res, next) => {
  try {
    const authHeader = req.headers['authorization'];
    const token = authHeader && authHeader.split(' ')[1]; // Bearer TOKEN
    
    if (!token) {
      return res.status(401).json({
        success: false,
        message: 'ØªÙˆÚ©Ù† Ø¯Ø³ØªØ±Ø³ÛŒ Ø§Ù„Ø²Ø§Ù…ÛŒ Ø§Ø³Øª'
      });
    }
    
    const authService = new AuthService();
    const decoded = authService.verifyAccessToken(token);
    
    // Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ú©Ø§Ø±Ø¨Ø±
    const user = await User.findById(decoded.userId).select('-password');
    if (!user) {
      return res.status(401).json({
        success: false,
        message: 'Ú©Ø§Ø±Ø¨Ø± ÛŒØ§ÙØª Ù†Ø´Ø¯'
      });
    }
    
    // Ø¨Ø±Ø±Ø³ÛŒ ÙØ¹Ø§Ù„ Ø¨ÙˆØ¯Ù† Ø­Ø³Ø§Ø¨
    if (!user.isActive) {
      return res.status(401).json({
        success: false,
        message: 'Ø­Ø³Ø§Ø¨ Ú©Ø§Ø±Ø¨Ø±ÛŒ ØºÛŒØ±ÙØ¹Ø§Ù„ Ø§Ø³Øª'
      });
    }
    
    req.user = user;
    next();
  } catch (error) {
    res.status(403).json({
      success: false,
      message: error.message
    });
  }
};

// controllers/authController.js
class AuthController {
  // Ø«Ø¨Øªâ€ŒÙ†Ø§Ù… Ú©Ø§Ø±Ø¨Ø± Ø¬Ø¯ÛŒØ¯
  async register(req, res) {
    try {
      const { name, email, password } = req.body;
      
      // Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ú©Ø§Ø±Ø¨Ø±
      const existingUser = await User.findOne({ email });
      if (existingUser) {
        return res.status(400).json({
          success: false,
          message: 'Ú©Ø§Ø±Ø¨Ø±ÛŒ Ø¨Ø§ Ø§ÛŒÙ† Ø§ÛŒÙ…ÛŒÙ„ Ù‚Ø¨Ù„Ø§Ù‹ Ø«Ø¨Øªâ€ŒÙ†Ø§Ù… Ú©Ø±Ø¯Ù‡ Ø§Ø³Øª'
        });
      }
      
      // Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ø±Ù…Ø² Ø¹Ø¨ÙˆØ±
      if (password.length < 8) {
        return res.status(400).json({
          success: false,
          message: 'Ø±Ù…Ø² Ø¹Ø¨ÙˆØ± Ø¨Ø§ÛŒØ¯ Ø­Ø¯Ø§Ù‚Ù„ 8 Ú©Ø§Ø±Ø§Ú©ØªØ± Ø¨Ø§Ø´Ø¯'
        });
      }
      
      const authService = new AuthService();
      const hashedPassword = await authService.hashPassword(password);
      
      // Ø§ÛŒØ¬Ø§Ø¯ Ú©Ø§Ø±Ø¨Ø± Ø¬Ø¯ÛŒØ¯
      const user = new User({
        name,
        email,
        password: hashedPassword,
        role: 'user',
        isActive: true
      });
      
      await user.save();
      
      // ØªÙˆÙ„ÛŒØ¯ tokens
      const tokens = authService.generateTokens(user._id);
      
      // Ø°Ø®ÛŒØ±Ù‡ refresh token Ø¯Ø± database
      user.refreshToken = tokens.refreshToken;
      await user.save();
      
      res.status(201).json({
        success: true,
        message: 'Ø«Ø¨Øªâ€ŒÙ†Ø§Ù… Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯',
        user: {
          id: user._id,
          name: user.name,
          email: user.email,
          role: user.role
        },
        tokens
      });
    } catch (error) {
      res.status(500).json({
        success: false,
        message: 'Ø®Ø·Ø§ Ø¯Ø± Ø«Ø¨Øªâ€ŒÙ†Ø§Ù…',
        error: error.message
      });
    }
  }
  
  // ÙˆØ±ÙˆØ¯ Ú©Ø§Ø±Ø¨Ø±
  async login(req, res) {
    try {
      const { email, password } = req.body;
      
      // ÛŒØ§ÙØªÙ† Ú©Ø§Ø±Ø¨Ø±
      const user = await User.findOne({ email });
      if (!user) {
        return res.status(401).json({
          success: false,
          message: 'Ø§ÛŒÙ…ÛŒÙ„ ÛŒØ§ Ø±Ù…Ø² Ø¹Ø¨ÙˆØ± Ø§Ø´ØªØ¨Ø§Ù‡ Ø§Ø³Øª'
        });
      }
      
      // Ø¨Ø±Ø±Ø³ÛŒ ÙØ¹Ø§Ù„ Ø¨ÙˆØ¯Ù† Ø­Ø³Ø§Ø¨
      if (!user.isActive) {
        return res.status(401).json({
          success: false,
          message: 'Ø­Ø³Ø§Ø¨ Ú©Ø§Ø±Ø¨Ø±ÛŒ ØºÛŒØ±ÙØ¹Ø§Ù„ Ø§Ø³Øª'
        });
      }
      
      // ØªØ£ÛŒÛŒØ¯ Ø±Ù…Ø² Ø¹Ø¨ÙˆØ±
      const authService = new AuthService();
      const isValidPassword = await authService.comparePassword(password, user.password);
      
      if (!isValidPassword) {
        return res.status(401).json({
          success: false,
          message: 'Ø§ÛŒÙ…ÛŒÙ„ ÛŒØ§ Ø±Ù…Ø² Ø¹Ø¨ÙˆØ± Ø§Ø´ØªØ¨Ø§Ù‡ Ø§Ø³Øª'
        });
      }
      
      // ØªÙˆÙ„ÛŒØ¯ tokens Ø¬Ø¯ÛŒØ¯
      const tokens = authService.generateTokens(user._id);
      
      // Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ refresh token Ùˆ Ø¢Ø®Ø±ÛŒÙ† ÙˆØ±ÙˆØ¯
      user.refreshToken = tokens.refreshToken;
      user.lastLogin = new Date();
      await user.save();
      
      res.json({
        success: true,
        message: 'ÙˆØ±ÙˆØ¯ Ù…ÙˆÙÙ‚ÛŒØªâ€ŒØ¢Ù…ÛŒØ²',
        user: {
          id: user._id,
          name: user.name,
          email: user.email,
          role: user.role
        },
        tokens
      });
    } catch (error) {
      res.status(500).json({
        success: false,
        message: 'Ø®Ø·Ø§ Ø¯Ø± ÙˆØ±ÙˆØ¯',
        error: error.message
      });
    }
  }
  
  // ØªØ§Ø²Ù‡â€ŒØ³Ø§Ø²ÛŒ token
  async refreshToken(req, res) {
    try {
      const { refreshToken } = req.body;
      
      if (!refreshToken) {
        return res.status(401).json({
          success: false,
          message: 'ØªÙˆÚ©Ù† ØªØ§Ø²Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø§Ù„Ø²Ø§Ù…ÛŒ Ø§Ø³Øª'
        });
      }
      
      const authService = new AuthService();
      const decoded = authService.verifyRefreshToken(refreshToken);
      
      // ÛŒØ§ÙØªÙ† Ú©Ø§Ø±Ø¨Ø± Ùˆ ØªØ£ÛŒÛŒØ¯ refresh token
      const user = await User.findById(decoded.userId);
      if (!user || user.refreshToken !== refreshToken) {
        return res.status(403).json({
          success: false,
          message: 'ØªÙˆÚ©Ù† ØªØ§Ø²Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù†Ø§Ù…Ø¹ØªØ¨Ø±'
        });
      }
      
      // ØªÙˆÙ„ÛŒØ¯ tokens Ø¬Ø¯ÛŒØ¯
      const newTokens = authService.generateTokens(user._id);
      
      // Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ refresh token
      user.refreshToken = newTokens.refreshToken;
      await user.save();
      
      res.json({
        success: true,
        tokens: newTokens
      });
    } catch (error) {
      res.status(403).json({
        success: false,
        message: 'Ø®Ø·Ø§ Ø¯Ø± ØªØ§Ø²Ù‡â€ŒØ³Ø§Ø²ÛŒ ØªÙˆÚ©Ù†',
        error: error.message
      });
    }
  }
  
  // Ø®Ø±ÙˆØ¬ Ú©Ø§Ø±Ø¨Ø±
  async logout(req, res) {
    try {
      const user = await User.findById(req.user.id);
      if (user) {
        user.refreshToken = null;
        await user.save();
      }
      
      res.json({
        success: true,
        message: 'Ø®Ø±ÙˆØ¬ Ù…ÙˆÙÙ‚ÛŒØªâ€ŒØ¢Ù…ÛŒØ²'
      });
    } catch (error) {
      res.status(500).json({
        success: false,
        message: 'Ø®Ø·Ø§ Ø¯Ø± Ø®Ø±ÙˆØ¬',
        error: error.message
      });
    }
  }
}

module.exports = { AuthController: new AuthController(), loginLimiter, authenticateToken };
```

### â˜ï¸ **Cloud Deployment**

#### Û±. AWS Lambda Function
```javascript
// Ø¯Ø±Ø®ÙˆØ§Ø³Øª: "ÛŒÚ© Lambda function Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµØ§ÙˆÛŒØ± Ø¨Ø³Ø§Ø²"

const AWS = require('aws-sdk');
const sharp = require('sharp');

// ØªÙ†Ø¸ÛŒÙ… AWS services
const s3 = new AWS.S3();
const sns = new AWS.SNS();

exports.handler = async (event) => {
  console.log('ğŸ“¸ Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµÙˆÛŒØ±:', JSON.stringify(event, null, 2));
  
  try {
    // Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø² S3 event
    const bucket = event.Records[0].s3.bucket.name;
    const key = decodeURIComponent(event.Records[0].s3.object.key.replace(/\+/g, ' '));
    
    console.log(`ğŸ“ Bucket: ${bucket}, Key: ${key}`);
    
    // Ø¯Ø§Ù†Ù„ÙˆØ¯ ØªØµÙˆÛŒØ± Ø§Ø² S3
    const originalImage = await s3.getObject({
      Bucket: bucket,
      Key: key
    }).promise();
    
    // ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
    const sizes = [
      { name: 'thumbnail', width: 150, height: 150 },
      { name: 'small', width: 400, height: 400 },
      { name: 'medium', width: 800, height: 600 },
      { name: 'large', width: 1200, height: 900 }
    ];
    
    const processedImages = [];
    
    // Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‡Ø± Ø§Ù†Ø¯Ø§Ø²Ù‡
    for (const size of sizes) {
      console.log(`ğŸ”„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø§Ù†Ø¯Ø§Ø²Ù‡ ${size.name}...`);
      
      const resizedImage = await sharp(originalImage.Body)
        .resize(size.width, size.height, {
          fit: 'inside',
          withoutEnlargement: true
        })
        .jpeg({
          quality: 85,
          progressive: true
        })
        .toBuffer();
      
      // Ø¢Ù¾Ù„ÙˆØ¯ ØªØµÙˆÛŒØ± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡
      const newKey = key.replace(/\.[^/.]+$/, `_${size.name}.jpg`);
      
      await s3.putObject({
        Bucket: bucket,
        Key: newKey,
        Body: resizedImage,
        ContentType: 'image/jpeg',
        CacheControl: 'max-age=31536000', // 1 Ø³Ø§Ù„
        Metadata: {
          'original-key': key,
          'size': size.name,
          'width': size.width.toString(),
          'height': size.height.toString()
        }
      }).promise();
      
      processedImages.push({
        size: size.name,
        key: newKey,
        dimensions: `${size.width}x${size.height}`
      });
      
      console.log(`âœ… ${size.name} Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯: ${newKey}`);
    }
    
    // Ø§Ø±Ø³Ø§Ù„ notification
    const message = {
      originalImage: key,
      processedImages: processedImages,
      bucket: bucket,
      timestamp: new Date().toISOString(),
      status: 'completed'
    };
    
    await sns.publish({
      TopicArn: process.env.SNS_TOPIC_ARN,
      Message: JSON.stringify(message),
      Subject: 'Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµÙˆÛŒØ± Ú©Ø§Ù…Ù„ Ø´Ø¯'
    }).promise();
    
    console.log('ğŸ“¤ Notification Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯');
    
    return {
      statusCode: 200,
      body: JSON.stringify({
        message: 'Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµÙˆÛŒØ± Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯',
        originalImage: key,
        processedImages: processedImages
      })
    };
    
  } catch (error) {
    console.error('âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµÙˆÛŒØ±:', error);
    
    // Ø§Ø±Ø³Ø§Ù„ error notification
    await sns.publish({
      TopicArn: process.env.SNS_ERROR_TOPIC_ARN,
      Message: JSON.stringify({
        error: error.message,
        stack: error.stack,
        event: event
      }),
      Subject: 'Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµÙˆÛŒØ±'
    }).promise();
    
    return {
      statusCode: 500,
      body: JSON.stringify({
        error: 'Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµÙˆÛŒØ±',
        message: error.message
      })
    };
  }
};
```

### ğŸ¤– **Automation Scripts**

#### Û±. CI/CD Pipeline
```yaml
# Ø¯Ø±Ø®ÙˆØ§Ø³Øª: "ÛŒÚ© GitHub Actions workflow Ú©Ø§Ù…Ù„ Ø¨Ø³Ø§Ø²"

name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

env:
  NODE_VERSION: '18'
  DOCKER_REGISTRY: 'ghcr.io'
  IMAGE_NAME: 'myapp'

jobs:
  # Ù…Ø±Ø­Ù„Ù‡ ØªØ³Øª Ùˆ Ø¨Ø±Ø±Ø³ÛŒ Ú©ÛŒÙÛŒØª
  test:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
    - name: ğŸ“¥ Checkout code
      uses: actions/checkout@v4
      
    - name: ğŸŸ¢ Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        
    - name: ğŸ“¦ Install dependencies
      run: |
        npm ci
        npm run install:all
        
    - name: ğŸ” Lint code
      run: |
        npm run lint
        npm run lint:css
        
    - name: ğŸ—ï¸ Build application
      run: npm run build
      
    - name: ğŸ§ª Run unit tests
      run: npm run test:unit
      env:
        CI: true
        
    - name: ğŸ”¬ Run integration tests
      run: npm run test:integration
      env:
        DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_db
        REDIS_URL: redis://localhost:6379
        
    - name: ğŸŒ Run E2E tests
      run: |
        npm run start:test &
        npm run test:e2e
        
    - name: ğŸ“Š Generate coverage report
      run: npm run test:coverage
      
    - name: ğŸ“¤ Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage/lcov.info
        
    - name: ğŸ”’ Security audit
      run: |
        npm audit --audit-level high
        npm run security:scan

  # Ù…Ø±Ø­Ù„Ù‡ build Ùˆ deploy
  deploy:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
    - name: ğŸ“¥ Checkout code
      uses: actions/checkout@v4
      
    - name: ğŸ³ Setup Docker Buildx
      uses: docker/setup-buildx-action@v3
      
    - name: ğŸ”‘ Login to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.DOCKER_REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
        
    - name: ğŸ·ï¸ Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.DOCKER_REGISTRY }}/${{ github.repository }}/${{ env.IMAGE_NAME }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=sha,prefix={{branch}}-
          type=raw,value=latest,enable={{is_default_branch}}
          
    - name: ğŸ—ï¸ Build and push Docker image
      uses: docker/build-push-action@v5
      with:
        context: .
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
        
    - name: â˜ï¸ Deploy to AWS ECS
      run: |
        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ECS service
        aws ecs update-service \
          --cluster production-cluster \
          --service myapp-service \
          --force-new-deployment
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_DEFAULT_REGION: us-east-1
        
    - name: ğŸ“¢ Notify Slack
      uses: 8398a7/action-slack@v3
      with:
        status: ${{ job.status }}
        channel: '#deployments'
        webhook_url: ${{ secrets.SLACK_WEBHOOK }}
      if: always()
```

## Ù†Ú©Ø§Øª Ø¹Ù…Ù„ÛŒ Ùˆ Ø¨Ù‡ØªØ±ÛŒÙ† Ø´ÛŒÙˆÙ‡â€ŒÙ‡Ø§

### ğŸ’¡ **Tips Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡**

#### Û±. ØªØ¹Ø§Ù…Ù„ Ù…Ø¤Ø«Ø± Ø¨Ø§ Agent
```text
âœ… Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ø®ÙˆØ¨:
"ÛŒÚ© React component Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù¾Ø±ÙˆÙØ§ÛŒÙ„ Ú©Ø§Ø±Ø¨Ø± Ø¨Ø³Ø§Ø² Ú©Ù‡ Ø´Ø§Ù…Ù„:
- Ù†Ù…Ø§ÛŒØ´ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø´Ø®ØµÛŒ
- Ø§Ù…Ú©Ø§Ù† ÙˆÛŒØ±Ø§ÛŒØ´
- validation Ø¨Ø±Ø§ÛŒ ÙØ±Ù…
- responsive design
- accessibility features"

âŒ Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ø¶Ø¹ÛŒÙ:
"ÛŒÚ© component Ø¨Ø³Ø§Ø²"
"Ú©Ø¯ Ø¨Ù†ÙˆÛŒØ³"
"Ø§ÛŒÙ† Ø±Ùˆ Ø¯Ø±Ø³Øª Ú©Ù†"
```

#### Û². Context Management
```text
âœ… Context Ù…Ø¤Ø«Ø±:
@src/components/UserProfile.tsx
@src/types/User.ts
@src/hooks/useUser.ts
@tests/UserProfile.test.tsx

âŒ Context ØºÛŒØ±Ù…Ø¤Ø«Ø±:
@src (Ø®ÛŒÙ„ÛŒ Ú¯Ø³ØªØ±Ø¯Ù‡)
@. (ØªÙ…Ø§Ù… Ù¾Ø±ÙˆÚ˜Ù‡)
```

#### Û³. Rules Ù…Ø¤Ø«Ø±
```markdown
# Ù‚ÙˆØ§Ù†ÛŒÙ† Ø®ÙˆØ¨:
## Ú©Ø¯Ù†ÙˆÛŒØ³ÛŒ
- Ù‡Ù…ÛŒØ´Ù‡ TypeScript Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
- Ø§Ø² functional components Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
- error boundaries Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†
- accessibility Ø±Ø§ Ø±Ø¹Ø§ÛŒØª Ú©Ù†

## ØªØ³Øª
- Ù‡Ø± component Ø¨Ø§ÛŒØ¯ unit test Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯
- coverage Ø­Ø¯Ø§Ù‚Ù„ 80% Ø¨Ø§Ø´Ø¯
- E2E test Ø¨Ø±Ø§ÛŒ user flows Ø§ØµÙ„ÛŒ

## Ø§Ù…Ù†ÛŒØª
- input validation Ø§Ù„Ø²Ø§Ù…ÛŒ
- SQL injection prevention
- XSS protection
```

---

## Ø®Ù„Ø§ØµÙ‡

Ø§ÛŒÙ† Ø¨Ø®Ø´ Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„ÛŒ Ø¬Ø§Ù…Ø¹ÛŒ Ø§Ø²:
- **Ù¾Ø±ÙˆÚ˜Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ¨ (Frontend/Backend)**
- **Ø§Ù¾Ù„ÛŒÚ©ÛŒØ´Ù†â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¨Ø§ÛŒÙ„**
- **Ù¾Ø±ÙˆÚ˜Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹Ù„ÙˆÙ… Ø¯Ø§Ø¯Ù‡**
- **Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ DevOps**
- **Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ automation**

Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ú©Ù‡ Ù†Ø´Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ú†Ú¯ÙˆÙ†Ù‡ Cursor Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¯Ø± Ø§Ù†ÙˆØ§Ø¹ Ù…Ø®ØªÙ„Ù Ù¾Ø±ÙˆÚ˜Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ Ø´Ù…Ø§ Ú©Ù…Ú© Ú©Ù†Ø¯.

---
*Ø§ÛŒÙ† Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒÛŒ Ø§Ø² Ù‚Ø¯Ø±Øª Cursor Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ú©Ø¯ Ú©ÛŒÙÛŒØª Ø¨Ø§Ù„Ø§ Ùˆ Ú©Ø§Ù…Ù„ Ù‡Ø³ØªÙ†Ø¯.*